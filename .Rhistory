LinDiscrimPrediction<-predict(LinearDiscriminantModel,testing)
StackedForest<-data.table(BoostPrediction,RandForPrediction,LinDiscrimPrediction,diagnosis=testing$diagnosis)
StackedPrediction<-predict(StackedForestModel,StackedForest)
confusionMatrix(BoostPrediction,testing$diagnosis)
confusionMatrix(RandForPrediction,testing$diagnosis)
confusionMatrix(LinDiscrimPrediction,testing$diagnosis)
confusionMatrix(StackedPrediction,testing$diagnosis)
StackedAccuracy<-sum(StackedPrediction==testing$diagnosis)/nrow(testing)
#machine learning Q4 # 2
library(caret)
library(gbm)
set.seed(62433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
BoostedModel <- train(diagnosis ~.,method="gbm",data=training)
RandomForestModel <- train(diagnosis ~.,method="rf",
data=training,
trControl = trainControl(method="cv"))
LinearDiscriminantModel<- train(diagnosis ~.,method="lda",data=training)
BoostPrediction<-predict(BoostedModel,training)
RandForPrediction<-predict(RandomForestModel,training)
LinDiscrimPrediction<-predict(LinearDiscriminantModel,training)
StackedForest<-data.table(BoostPrediction,RandForPrediction,LinDiscrimPrediction,diagnosis=training$diagnosis)
StackedForestModel <- train(diagnosis ~.,method="rf",
data=StackedForest,
trControl = trainControl(method="cv"))
BoostPrediction<-predict(BoostedModel,testing)
RandForPrediction<-predict(RandomForestModel,testing)
LinDiscrimPrediction<-predict(LinearDiscriminantModel,testing)
StackedForest<-data.table(BoostPrediction,RandForPrediction,LinDiscrimPrediction,diagnosis=testing$diagnosis)
StackedPrediction<-predict(StackedForestModel,StackedForest)
confusionMatrix(BoostPrediction,testing$diagnosis)
confusionMatrix(RandForPrediction,testing$diagnosis)
confusionMatrix(LinDiscrimPrediction,testing$diagnosis)
confusionMatrix(StackedPrediction,testing$diagnosis)
StackedAccuracy<-sum(StackedPrediction==testing$diagnosis)/nrow(testing)
#machine learning Q4 # 2
library(caret)
library(gbm)
set.seed(62432)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
BoostedModel <- train(diagnosis ~.,method="gbm",data=training)
RandomForestModel <- train(diagnosis ~.,method="rf",
data=training,
trControl = trainControl(method="cv"))
LinearDiscriminantModel<- train(diagnosis ~.,method="lda",data=training)
BoostPrediction<-predict(BoostedModel,training)
RandForPrediction<-predict(RandomForestModel,training)
LinDiscrimPrediction<-predict(LinearDiscriminantModel,training)
StackedForest<-data.table(BoostPrediction,RandForPrediction,LinDiscrimPrediction,diagnosis=training$diagnosis)
StackedForestModel <- train(diagnosis ~.,method="rf",
data=StackedForest,
trControl = trainControl(method="cv"))
BoostPrediction<-predict(BoostedModel,testing)
RandForPrediction<-predict(RandomForestModel,testing)
LinDiscrimPrediction<-predict(LinearDiscriminantModel,testing)
StackedForest<-data.table(BoostPrediction,RandForPrediction,LinDiscrimPrediction,diagnosis=testing$diagnosis)
StackedPrediction<-predict(StackedForestModel,StackedForest)
confusionMatrix(BoostPrediction,testing$diagnosis)
confusionMatrix(RandForPrediction,testing$diagnosis)
confusionMatrix(LinDiscrimPrediction,testing$diagnosis)
confusionMatrix(StackedPrediction,testing$diagnosis)
StackedAccuracy<-sum(StackedPrediction==testing$diagnosis)/nrow(testing)
library("RGtk2", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("MASS", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("lattice", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("data.table", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("randomForest", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("plyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("dplyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
?plot.enet
?plot.enet()
??plot.enet()
?plot.enet()
install.packages("lars")
library("lars", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
set.seed(233)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
head(training)
LassoFit<-train(CompressiveStrength~.,data=training,method="lasso")
install.packages("elasticnet")
plot.enet(LassoFit)
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("RGtk2", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
plot.enet(LassoFit)
library("lars", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
plot.enet(LassoFit)
names(LassoFit)
LassoFit$results
LassoFit$finalModel
library("elasticnet", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
plot.enet(LassoFit)
plot.enet(LassoFit$results)
plot.enet(LassoFit$finalModel)
install.packages("forecast")
?download.file()
BlogVisitsFile<-tempfile()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",
"./gaData.csv",
"curl")
library(forecast)
library(lubridate)  # For year() function below
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("lubridate")
BlogVisitsFile<-tempfile()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",
"./gaData.csv",
"curl")
library(forecast)
library(lubridate)  # For year() function below
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
head(dat)
?forecast()
BatsModel<-bats(training)
BatsModel<-bats(tstrain)
names(BatsModel)
BatsModel$fitted.values
BatsPrediction<-forecast.bats(BatsModel,testing,level=.95)
BatsPrediction<-forecast.bats(BatsModel,h=nrow(testing),data=testing,level=.95)
names(BatsPrediction)
BatsPrediction$model
BatsPrediction$mean
BatsPrediction$level
BatsPrediction$x
BatsPrediction$upper
BatsPrediction$lower
BatsPrediction$fitted
names(BatsPrediction)
BatsPrediction$method
BatsPrediction$residuals
InBounds<-testing$visitsTumblr<=BatsPrediction$upper & testing$visitsTumblr>=BatsPrediction$lower
Correct95<-sum(InBounds)/nrow(testing)
InBounds<-testing$visitsTumblr>=BatsPrediction$upper & testing$visitsTumblr<=BatsPrediction$lower
Correct95<-sum(InBounds)/nrow(testing)
Correct95
BatsModel<-bats(tstrain)
BatsPrediction<-forecast.bats(BatsModel,data=testing,level=.95)
InBounds<-testing$visitsTumblr>=BatsPrediction$upper & testing$visitsTumblr<=BatsPrediction$lower
Correct95<-sum(InBounds)/nrow(testing)
Correct95
BatsModel<-bats(training)
BatsPrediction<-forecast.bats(BatsModel,data=testing,level=.95)
InBounds<-testing$visitsTumblr>=BatsPrediction$upper & testing$visitsTumblr<=BatsPrediction$lower
Correct95<-sum(InBounds)/nrow(testing)
Correct95
BatsModel<-bats(training)
BatsPrediction<-forecast.bats(BatsModel,h=nrow(testing)data=testing,level=.95)
InBounds<-testing$visitsTumblr>=BatsPrediction$upper & testing$visitsTumblr<=BatsPrediction$lower
Correct95<-sum(InBounds)/nrow(testing)
Correct95
BatsModel<-bats(tstrain)
BatsPrediction<-forecast.bats(BatsModel,h=length(tstest),data=tstest,level=.95)
InBounds<-testing$visitsTumblr>=BatsPrediction$upper & testing$visitsTumblr<=BatsPrediction$lower
Correct95<-sum(InBounds)/nrow(testing)
Correct95
tstest=ts(testing$visitsTumblr)
BatsModel<-bats(tstrain)
BatsPrediction<-forecast.bats(BatsModel,h=length(tstest),data=tstest,level=.95)
InBounds<-testing$visitsTumblr>=BatsPrediction$upper & testing$visitsTumblr<=BatsPrediction$lower
Correct95<-sum(InBounds)/nrow(testing)
Correct95
tstest=ts(testing$visitsTumblr)
BatsModel<-bats(tstrain)
BatsPrediction<-forecast.bats(BatsModel,h=length(tstest),data=tstest,level=.95)
InBounds<-testing$visitsTumblr<=BatsPrediction$upper & testing$visitsTumblr>=BatsPrediction$lower
Correct95<-sum(InBounds)/nrow(testing)
Correct95
View(InBounds)
plot(BatsPrediction$x,testing$visitsTumblr)
BatsPrediction$mean
plot(BatsPrediction$mean,testing$visitsTumblr)
BatsModel<-bats(tstest)
BatsPrediction<-forecast.bats(BatsModel,h=length(tstest),data=tstest,level=.95)
InBounds<-testing$visitsTumblr<=BatsPrediction$upper & testing$visitsTumblr>=BatsPrediction$lower
Correct95<-sum(InBounds)/nrow(testing)
Correct95
?ets()
?bats()
BatsModel<-bats(tstrain,use.parallel=FALSE)
BatsPrediction<-forecast.bats(BatsModel,h=length(tstest),data=tstest,level=.95)
InBounds<-testing$visitsTumblr<=BatsPrediction$upper & testing$visitsTumblr>=BatsPrediction$lower
Correct95<-sum(InBounds)/nrow(testing)
Correct95
names(BatsPrediction)
BatsPrediction$fitted
BatsModel<-bats(tstrain,use.parallel=FALSE)
BatsPrediction<-forecast.bats(BatsModel,h=length(tstest),level=.95)
InBounds<-testing$visitsTumblr<=BatsPrediction$upper & testing$visitsTumblr>=BatsPrediction$lower
Correct95<-sum(InBounds)/nrow(testing)
Correct95
BatsModel<-bats(tstrain,use.parallel=FALSE)
BatsPrediction<-forecast(BatsModel,h=length(tstest),level=.95)
plot(BatsPrediction)
lines=(tstest)
accuracy(BatsPrediction,tstest)
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstest=ts(testing$visitsTumblr)
BatsModel<-bats(tstest,use.parallel=FALSE)
BatsPrediction<-forecast(BatsModel,h=length(tstrain),level=.95)
plot(BatsPrediction)
lines=(tstrain)
accuracy(BatsPrediction,tstrain)
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstest=ts(testing$visitsTumblr)
BatsModel<-bats(tstest,use.parallel=FALSE)
BatsPrediction<-forecast(BatsModel,h=length(tstrain),level=.95)
plot(BatsPrediction)
lines=(tstest)
accuracy(BatsPrediction,tstrain)
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
tstest=ts(testing$visitsTumblr)
BatsModel<-bats(tstrain)
BatsPrediction<-forecast(BatsModel)
plot(BatsPrediction)
lines=(tstest)
accuracy(BatsPrediction,tstest)
plot(BatsPrediction)
plot(tstest)
plot(tstrain)
overallts<-merge(tstrain,tstest)
plot(overall(ts)
)
plot(overallts)
library("e1071", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
View(training)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
SVMmodel<-svm(CompressiveStrength~.,data=training)
SVMPredict<-predict(SVMmodel,data=testing)
View(testing)
RMSE<-sum((testing$CompressiveStrength-SVMPredict)^2)/length(SVMPredict)
?predict()
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
SVMmodel<-svm(CompressiveStrength~.,data=training)
SVMPredict<-predict.svm(SVMmodel,data=testing)
detach("package:e1071", unload=TRUE)
library("e1071", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
?predict.svm()
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
SVMmodel<-svm(CompressiveStrength~.,data=training)
SVMPredict<-predict.svm(SVMmodel,newdata=testing)
names(SVMmodel)
SVMmodel$coefs
names(SVMmodel)
?forecast()
BlogVisitsFile<-tempfile()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",
"./gaData.csv",
"curl")
library(forecast)
library(lubridate)  # For year() function below
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
BatsModel<-bats(tstrain)
BatsPrediction<-forecast(BatsModel,h=length(testing$visitsTumblr),level=.95)
names(BatsPrediction)
names(BatsPrediction$model)
BatsPrediction$model$fitted.values
BatsPrediction$model$variance
sqrt(BatsPrediction$model$variance)/365
names(BatsPrediction)
names(BatsPrediction$fitted)
BatsPrediction$fitted
round(BatsPrediction$fitted)
plot(BatsPredicted$fitted,testing$visitsTumblr)
plot(BatsPrediction$fitted,testing$visitsTumblr)
length(testing$visitsTumblr)
BlogVisitsFile<-tempfile()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",
"./gaData.csv",
"curl")
library(forecast)
library(lubridate)  # For year() function below
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
BatsModel<-bats(tstrain)
BatsPrediction<-forecast(BatsModel,h=235,level=.95)
plot(BatsPrediction$fitted,testing$visitsTumblr)
BatsPrediction$fitted
BlogVisitsFile<-tempfile()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",
"./gaData.csv",
"curl")
library(forecast)
library(lubridate)  # For year() function below
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
BatsModel<-bats(tstrain)
BatsPrediction<-forecast.bats(BatsModel,h=235,level=.95)
BatsPrediction$mean
BatsPrediction$fitted
BatsPrediction$upper
BatsPrediction$lower
?forecast.bats()
BatsPrediction$x
BatsPrediction$model
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("data.table", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("e1071", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
SVMmodel<-svm(CompressiveStrength~.,data=training)
SVMPredict<-predict.svm(SVMmodel,newdata=testing)
SVMPredict<-predict(SVMmodel,newdata=testing)
length(SVMPredict)
length(testing$CompressiveStrength)
sum((testing$CompressiveStrength-SVMPredict)^2)
sum((testing$CompressiveStrength-SVMPredict)^2)/256
sqrt(sum((testing$CompressiveStrength-SVMPredict)^2)/256)
sqrt(11543.39)
library("forecast", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
?ts()
BlogVisitsFile<-tempfile()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",
"./gaData.csv",
"curl")
library(forecast)
library(lubridate)  # For year() function below
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr,start=236)
BatsModel<-bats(tstrain[236:600])
BatsPrediction<-forecast.bats(BatsModel,h=235,level=.95)
tail(tstrain)
tstrain[225:255]
BlogVisitsFile<-tempfile()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",
"./gaData.csv",
"curl")
library(forecast)
library(lubridate)  # For year() function below
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(dat$visitsTumblr,start=236)
BatsModel<-bats(tstrain)
BatsPrediction<-forecast.bats(BatsModel,h=235,level=.95)
head(training)
tail(training)
head(testing)
tail(testing()
tail(testing)
head(tstrain)
tail(tstrain)
head(dat)
BlogVisitsFile<-tempfile()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",
"./gaData.csv",
"curl")
library(forecast)
library(lubridate)  # For year() function below
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
BatsModel<-bats(tstrain)
BatsPrediction<-forecast.bats(BatsModel,h=235,level=.95)
names(BatsPrediction)
BatsPrediction$mean
BatsPrediction$upper
BatsPrediction$lower
BlogVisitsFile<-tempfile()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",
"./gaData.csv",
"curl")
library(forecast)
library(lubridate)  # For year() function below
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
BatsModel<-bats(tstrain)
BatsPrediction<-forecast(BatsModel,h=235,level=.95)
BatsPrediction$lower
?forecast.bats()
BlogVisitsFile<-tempfile()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",
"./gaData.csv",
"curl")
library(forecast)
library(lubridate)  # For year() function below
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
BatsModel<-bats(tstrain)
BatsPrediction<-forecast(BatsModel,h=235,level=95)
BatsPrediction$upper
BatsPrediction$lower
BlogVisitsFile<-tempfile()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",
"./gaData.csv",
"curl")
library(forecast)
library(lubridate)  # For year() function below
dat = read.csv("./gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
BatsModel<-bats(tstrain)
BatsPrediction<-forecast(BatsModel,h=235,level=95)
BatsRightsUnder<-testing$visitsTumblr<=BatsPrediction$upper
BatsRightsOver<-testing$visitsTumblr>=BatsPrediction$lower
BatsRightsAll<-BatsRightsUnder & BatsRightsOver
sum(BatsRightsAll)
sum(BatsRightsAll)/length(testing$visitsTumblr)
#machine learning Q4 # 2
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62432)
BoostedModel <- train(diagnosis ~.,method="gbm",data=training)
RandomForestModel <- train(diagnosis ~.,method="rf",
data=training,
trControl = trainControl(method="cv"))
LinearDiscriminantModel<- train(diagnosis ~.,method="lda",data=training)
BoostPrediction<-predict(BoostedModel,training)
RandForPrediction<-predict(RandomForestModel,training)
LinDiscrimPrediction<-predict(LinearDiscriminantModel,training)
StackedForest<-data.table(BoostPrediction,RandForPrediction,LinDiscrimPrediction,diagnosis=training$diagnosis)
StackedForestModel <- train(diagnosis ~.,method="rf",
data=StackedForest,
trControl = trainControl(method="cv"))
BoostPrediction<-predict(BoostedModel,testing)
RandForPrediction<-predict(RandomForestModel,testing)
LinDiscrimPrediction<-predict(LinearDiscriminantModel,testing)
StackedForest<-data.table(BoostPrediction,RandForPrediction,LinDiscrimPrediction,diagnosis=testing$diagnosis)
StackedPrediction<-predict(StackedForestModel,StackedForest)
confusionMatrix(BoostPrediction,testing$diagnosis)
confusionMatrix(RandForPrediction,testing$diagnosis)
confusionMatrix(LinDiscrimPrediction,testing$diagnosis)
confusionMatrix(StackedPrediction,testing$diagnosis)
StackedAccuracy<-sum(StackedPrediction==testing$diagnosis)/nrow(testing)
list.files
list.files()
setwd("./RepData_PeerAssessment1")
getwd()
list.files()
library("knitr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
knit2html("./PA1_template.Rmd")
